{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyccl as ccl\n",
    "import sacc\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import tjpcov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccl.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosmo = ccl.Cosmology(Omega_c = 0.27, Omega_b = 0.045, h = 0.67, sigma8 = 0.83, n_s = 0.96,transfer_function='boltzmann_class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twopoint_data = sacc.Sacc.load_fits('twopoint_data.sacc') #provided by Emily Longley"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twopoint_data.metadata['fsky']=0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2r=np.pi/180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIXME: ell_bins and th_bins should be passed by sacc. ell0 and th can be decided based on binning or can also be passed by sacc.\n",
    "twopoint_data.metadata['ell']=np.arange(2,500)\n",
    "twopoint_data.metadata['ell_bins']=np.arange(2,500,20)\n",
    "th_min=2.5/60 # in degrees\n",
    "th_max=250./60\n",
    "n_th_bins=20\n",
    "twopoint_data.metadata['th_bins']=np.logspace(np.log10(th_min),np.log10(th_max),n_th_bins+1)\n",
    "\n",
    "th=np.logspace(np.log10(th_min*0.98),np.log10(1),n_th_bins*30) #covariance is oversampled at th values and then binned.\n",
    "th2=np.linspace(1,th_max*1.02,n_th_bins*30) #binned covariance can be sensitive to the th values. Make sue you check convergence for your application\n",
    "# th2=np.logspace(np.log10(1),np.log10(th_max),60*6)\n",
    "twopoint_data.metadata['th']=np.unique(np.sort(np.append(th,th2)))\n",
    "thb=0.5*(twopoint_data.metadata['th_bins'][1:]+twopoint_data.metadata['th_bins'][:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The spin based factor to decide the wigner transform. Based on spin of tracers. Sometimes we may use s1_s2 to denote these factors\n",
    "WT_factors={}\n",
    "WT_factors['lens','source']=(0,2)\n",
    "WT_factors['source','lens']=(2,0) #same as (0,2)\n",
    "WT_factors['source','source']={'plus':(2,2),'minus':(2,-2)}\n",
    "WT_factors['lens','lens']=(0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Wigner Transform setup... \n",
    "WT_kwargs={'l': twopoint_data.metadata['ell'],'theta': twopoint_data.metadata['th']*d2r,'s1_s2':[(2,2),(2,-2),(0,2),(2,0),(0,0)]}\n",
    "%time WT=tjpcov.wigner_transform(**WT_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(twopoint_data.get_tracer_combinations())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twopoint_data.get_data_types()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twopoint_data.tracers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function will generate and return CCL_tracer objects and also compute the noise for all the tracers\n",
    "def get_tracer_info(two_point_data={}):\n",
    "    ccl_tracers={}\n",
    "    tracer_Noise={}\n",
    "    for tracer in twopoint_data.tracers:\n",
    "        tracer_dat=twopoint_data.get_tracer(tracer)\n",
    "        z= tracer_dat.z\n",
    "        #FIXME: Following should be read from sacc dataset.\n",
    "        Ngal = 26. #arc_min^2\n",
    "        sigma_e=.26 #shape noise per component.\n",
    "        b = 1.5*np.ones(len(z)) #Galaxy bias (constant with scale and z)\n",
    "        AI = .5*np.ones(len(z)) #Galaxy bias (constant with scale and z)\n",
    "        Ngal=Ngal*3600/d2r**2\n",
    "        #red_frac=0.2*np.ones(len(z))\n",
    "        \n",
    "        dNdz = tracer_dat.nz\n",
    "        dNdz/=(dNdz*np.gradient(z)).sum()\n",
    "        dNdz*=Ngal\n",
    "        \n",
    "        if 'source' in tracer:  \n",
    "            ccl_tracers[tracer]=ccl.WeakLensingTracer(cosmo, dndz=(z, dNdz),ia_bias=(z,AI)) #CCL automatically normalizes dNdz\n",
    "            tracer_Noise[tracer]=sigma_e**2/Ngal\n",
    "        elif 'lens' in tracer:\n",
    "            tracer_Noise[tracer]=1./Ngal\n",
    "            ccl_tracers[tracer]=ccl.NumberCountsTracer(cosmo, has_rsd=False, dndz=(z,dNdz), bias=(z,b))\n",
    "    return ccl_tracers,tracer_Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cov_WT_spin(tracer_comb=None):\n",
    "    tracers=tuple(i.split('_')[0] for i in tracer_comb)\n",
    "    return WT_factors[tracers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute a single covariance matrix for a given pair of C_ell or xi.  \n",
    "def cl_gaussian_cov(tracer_comb1=None,tracer_comb2=None,ccl_tracers=None,tracer_Noise=None,two_point_data=None,do_xi=False,\n",
    "                    xi_plus_minus1='plus',xi_plus_minus2='plus'):  \n",
    "    #fsky should be read from the sacc\n",
    "    #tracers 1,2,3,4=tracer_comb1[0],tracer_comb1[1],tracer_comb2[0],tracer_comb2[1]\n",
    "    ell=two_point_data.metadata['ell']\n",
    "    cl={}\n",
    "    cl[13] = ccl.angular_cl(cosmo, ccl_tracers[tracer_comb1[0]], ccl_tracers[tracer_comb2[0]], ell)\n",
    "    cl[24] = ccl.angular_cl(cosmo, ccl_tracers[tracer_comb1[1]], ccl_tracers[tracer_comb2[1]], ell)\n",
    "    cl[14] = ccl.angular_cl(cosmo, ccl_tracers[tracer_comb1[0]], ccl_tracers[tracer_comb2[1]], ell)\n",
    "    cl[23] = ccl.angular_cl(cosmo, ccl_tracers[tracer_comb1[1]], ccl_tracers[tracer_comb2[0]], ell)\n",
    "    \n",
    "    SN={}\n",
    "    SN[13]=tracer_Noise[tracer_comb1[0]] if tracer_comb1[0]==tracer_comb2[0]  else 0\n",
    "    SN[24]=tracer_Noise[tracer_comb1[1]] if tracer_comb1[1]==tracer_comb2[1]  else 0\n",
    "    SN[14]=tracer_Noise[tracer_comb1[0]] if tracer_comb1[0]==tracer_comb2[1]  else 0\n",
    "    SN[23]=tracer_Noise[tracer_comb1[1]] if tracer_comb1[1]==tracer_comb2[0]  else 0\n",
    "    \n",
    "    if do_xi:\n",
    "        norm=np.pi*4*two_point_data.metadata['fsky']\n",
    "    else: #do c_ell\n",
    "        norm=(2*ell+1)*np.gradient(ell)*two_point_data.metadata['fsky']\n",
    "\n",
    "    coupling_mat={}\n",
    "    coupling_mat[1324]=np.eye(len(ell)) #placeholder\n",
    "    coupling_mat[1423]=np.eye(len(ell)) #placeholder\n",
    "    \n",
    "    cov={}\n",
    "    cov[1324]=np.outer(cl[13]+SN[13],cl[24]+SN[24])*coupling_mat[1324]\n",
    "    cov[1423]=np.outer(cl[14]+SN[14],cl[23]+SN[23])*coupling_mat[1423]\n",
    "    \n",
    "    if self.do_xi and np.all(np.array(tracers)=='shear'): #this add the B-mode shape noise contribution. We assume B-mode power (C_ell) is 0\n",
    "        Bmode_F=1\n",
    "        if xi_plus_minus1!=xi_plus_minus2:\n",
    "            Bmode_F=-1 #in the cross term, this contribution is subtracted. eq. 29-31 of https://arxiv.org/pdf/0708.0387.pdf\n",
    "        cov[1324]+=np.outer(cl[13]*0+SN[13],cl[24]*0+SN[24])*coupling_mat[1324]*Bmode_F\n",
    "        cov[1423]+=np.outer(cl[14]*0+SN[14],cl[23]*0+SN[23])*coupling_mat[1423]*Bmode_F\n",
    "        \n",
    "    cov['final']=cov[1423]+cov[1324]\n",
    "    \n",
    "    if do_xi:\n",
    "        s1_s2_1=get_cov_WT_spin(tracer_comb=tracer_comb1)\n",
    "        s1_s2_2=get_cov_WT_spin(tracer_comb=tracer_comb2)\n",
    "        \n",
    "        if isinstance(s1_s2_1,dict):\n",
    "            s1_s2_1=s1_s2_1[xi_plus_minus1] \n",
    "        if isinstance(s1_s2_2,dict):\n",
    "            s1_s2_2=s1_s2_2[xi_plus_minus2]\n",
    "            \n",
    "        th,cov['final']=WT.projected_covariance2(l_cl=ell,s1_s2=s1_s2_1, s1_s2_cross=s1_s2_2,\n",
    "                                                      cl_cov=cov['final'])\n",
    "\n",
    "    cov['final']/=norm\n",
    "    \n",
    "    if do_xi:\n",
    "        thb,cov['final_b']=tjpcov.bin_cov(r=th/d2r,r_bins=two_point_data.metadata['th_bins'],cov=cov['final']) \n",
    "    else:\n",
    "        if two_point_data.metadata['ell_bins'] is not None:\n",
    "            lb,cov['final_b']=tjpcov.bin_cov(r=ell,r_bins=two_point_data.metadata['ell_bins'],cov=cov['final']) \n",
    "            \n",
    "#     cov[1324]=None #if want to save memory\n",
    "#     cov[1423]=None #if want to save memory\n",
    "    return cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute all the covariances and then combine them into one single giant matrix\n",
    "def get_all_cov(two_point_data={},do_xi=False):\n",
    "    #FIXME: Only input needed should be two_point_data, which is the sacc data file. Other parameters should be included within sacc and read from there.\n",
    "    ccl_tracers,tracer_Noise=get_tracer_info(two_point_data=two_point_data)\n",
    "    tracer_combs=two_point_data.get_tracer_combinations()# we will loop over all these\n",
    "    N2pt=len(tracer_combs)\n",
    "    if two_point_data.metadata['ell_bins'] is not None:\n",
    "        Nell_bins=len(two_point_data.metadata['ell_bins'])-1\n",
    "    else:\n",
    "        Nell_bins=len(two_point_data.metadata['ell'])\n",
    "    if do_xi:\n",
    "        Nell_bins=len(two_point_data.metadata['th_bins'])-1\n",
    "    cov_full=np.zeros((Nell_bins*N2pt,Nell_bins*N2pt))\n",
    "    for i in np.arange(N2pt):\n",
    "        print(\"{}/{}\".format(i+1, N2pt))\n",
    "        tracer_comb1=tracer_combs[i]\n",
    "        indx_i=i*Nell_bins\n",
    "        for j in np.arange(i,N2pt):\n",
    "            tracer_comb2=tracer_combs[j]\n",
    "            indx_j=j*Nell_bins\n",
    "            cov_ij=cl_gaussian_cov(tracer_comb1=tracer_comb1,tracer_comb2=tracer_comb2,ccl_tracers=ccl_tracers,\n",
    "                                        tracer_Noise=tracer_Noise,do_xi=do_xi,two_point_data=two_point_data)\n",
    "            if do_xi or two_point_data.metadata['ell_bins'] is not None:\n",
    "                cov_ij=cov_ij['final_b']\n",
    "            else:\n",
    "                cov_ij=cov_ij['final']\n",
    "            cov_full[indx_i:indx_i+Nell_bins,indx_j:indx_j+Nell_bins]=cov_ij\n",
    "            cov_full[indx_j:indx_j+Nell_bins,indx_i:indx_i+Nell_bins]=cov_ij.T\n",
    "    return cov_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#C_ell covariance\n",
    "cov_cl=get_all_cov(two_point_data=twopoint_data,do_xi=False)\n",
    "#xi covariance .... right now shear-shear is xi+ only. xi- needs to be added in the loops.\n",
    "cov_xi=get_all_cov(two_point_data=twopoint_data,do_xi=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err=np.sqrt(np.diag(cov_cl))\n",
    "corr_m=cov_cl/np.outer(err,err)\n",
    "pcolor(corr_m,vmin=-1,vmax=1,cmap='seismic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err=np.sqrt(np.diag(cov_xi))\n",
    "corr_m=cov_xi/np.outer(err,err)\n",
    "pcolor(corr_m,vmin=-1,vmax=1,cmap='seismic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
